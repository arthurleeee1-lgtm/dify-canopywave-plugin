model: deepseek/deepseek-chat-v3.2
label:
  zh_Hans: DeepSeek-V3.2
  en_US: DeepSeek-V3.2
model_type: llm
features:
  - stream-tool-call
  - vision
  - tool-call
model_properties:
  mode: chat
  context_size: 131072 # Assuming similar to 3.1 as not specified
parameter_rules:
  - name: temperature
    use_template: temperature
  - name: top_p
    use_template: top_p
  - name: presence_penalty
    use_template: presence_penalty
  - name: frequency_penalty
    use_template: frequency_penalty
  - name: max_tokens
    use_template: max_tokens
    default: 4096
    min: 1
    max: 8192
pricing:
  input: "26.00"
  output: "40.00"
  unit: "0.000001"
  currency: USD
