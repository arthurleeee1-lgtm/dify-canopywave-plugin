# Canopy Wave

**Author:** arthur  
**Version:** 0.0.5  
**Type:** model

## Description

Canopy Wave plugin provides access to state-of-the-art large language models hosted on Canopy Wave's high-performance inference platform.

This plugin enables Dify users to leverage powerful AI models through a simple API integration.

## Supported Models

| Model                       | Description                        |
| --------------------------- | ---------------------------------- |
| deepseek/deepseek-chat-v3.1 | DeepSeek V3.1 chat model           |
| deepseek/deepseek-chat-v3.2 | DeepSeek V3.2 chat model           |
| zai/glm-4.7                 | GLM-4.7 chat model                 |
| minimax/minimax-m2.1        | MiniMax M2.1 chat model            |
| moonshotai/kimi-k2-thinking | Kimi K2 thinking model             |
| moonshotai/kimi-k2.5        | Kimi K2.5 multimodal agentic model |
| xiaomimimo/mimo-v2-flash    | MIMO V2 Flash model                |

## Setup

1. **Get API Key**: Obtain an API key from [Canopy Wave Cloud](https://cloud.canopywave.io/model-api-key)
2. **Install Plugin**: Install this plugin in your Dify workspace
3. **Configure**: Add your API key in the model provider settings
4. **Use**: Select any Canopy Wave model for your Dify applications

## Features

- ✅ Streaming and non-streaming responses
- ✅ Multi-turn conversation support
- ✅ System prompts
- ✅ Temperature and Top-P control
- ✅ Presence and frequency penalty

## Links

- [Canopy Wave Website](https://canopywave.com)
- [API Documentation](https://canopywave.com/docs)
- [Support](https://ticket.canopywave.io/otobo/customer.pl)
